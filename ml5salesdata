Implement K-Means clustering/ hierarchical clustering on sales_data_sample.csv dataset. 
Determine the number of clusters using the elbow method.


import pandas as pd
import seaborn as sns
import numpy as np
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

#%%
df=pd.read_csv('C:/Users/sanyo/Desktop/Machine Learning/Machine Learning/sales_data_sample.csv',encoding='Latin-1')
df.head()
#%%   DATA PREPROCESSING 
# 1. REMOVE NULL VALUE 
df.isna().sum()
df.dropna(inplace=True)
df.isna().sum()

#%%
#2. DUPLICATE REMOVE
df.drop_duplicates(inplace=True)
#%%
#EDA 
df.info()
df.describe()    
df.columns
#%%
df.drop(["ORDERNUMBER", "PRICEEACH", "ORDERDATE", "PHONE", "ADDRESSLINE1", "ADDRESSLINE2", "CITY", "STATE", "TERRITORY", "POSTALCODE", "CONTACTLASTNAME", "CONTACTFIRSTNAME"], axis = 1, inplace=True)
df.head()
#%%
sns.histplot(x = 'SALES' , hue = 'PRODUCTLINE', data = df,element="poly")
#we can see all the catagory lies in the range of price
#%%
list_cat = df.select_dtypes(include=['object']).columns.tolist()
list_cat
#dealing with the catagorical features 
from sklearn import preprocessing
le = preprocessing.LabelEncoder()

# Encode labels in column 'species'.
for i in list_cat:
  df[i]= le.fit_transform(df[i])
#%%
## taget feature are Sales and productline
X = df[['SALES','PRODUCTCODE']] 
#%%
wcss=[]
for i in range(1,11):
    km=KMeans(n_clusters=i)
    km.fit(X)
    wcss.append(km.inertia_)
#The elbow curve
plt.figure(figsize=(12,6))
plt.plot(range(1,11),wcss)
plt.plot(range(1,11),wcss, linewidth=2, color="red", marker ="8")
plt.xlabel("K Value")
plt.xticks(np.arange(1,11,1))
plt.ylabel("WCSS")
plt.show()
#%%
kmeans = KMeans(n_clusters=11).fit(X)
#%%
kmeans.labels_
